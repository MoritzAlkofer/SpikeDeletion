{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from local_utils import Config, all_bipolar,four_bipolar, all_referential, two_referential, cut_and_jitter, build_montage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm   \n",
    "\n",
    "# load own code\n",
    "import sys\n",
    "sys.path.append('/home/moritz/Desktop/programming/epilepsy_project/')\n",
    "from librarys.event.model.model import FineTuning\n",
    "from librarys.event.datasets import SpikeDataset\n",
    "from librarys.general.channel_lists import CDAC_mono_channels\n",
    "from librarys.general.montages import build_montagev2\n",
    "from librarys.event.transforms import cut_and_jitter,delete_channels\n",
    "# this holds all the configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiSourceSpikeDataset(Dataset):\n",
    "    def __init__(self, df, metadata, montage_channels, windowcutter = None,transform=None,normalize=False,echo=True):\n",
    "        \n",
    "        if echo: print(f'building dataset from {metadata.keys()}')\n",
    "        # set lookup table\n",
    "        self.df = df\n",
    "        # set metadata\n",
    "        self.metadata = metadata\n",
    "        # set transform\n",
    "        self.transform = transform\n",
    "        # set windowcutter\n",
    "        self.windowcutter = windowcutter\n",
    "        # set normalize\n",
    "        self.normalize = normalize\n",
    "        if echo:\n",
    "            if self.normalize: print('Dataloader normalizes!\\n')\n",
    "            else: print('Dataloader does not normalize!\\n')\n",
    "\n",
    "        # generate montages for all datasets\n",
    "        self.montages = {}\n",
    "        for dataset in metadata.keys():\n",
    "            if echo: print('build montage for dataset ' + dataset + ' ...')\n",
    "            montage = build_montage(storage_channels=metadata[dataset]['storage_channels'], \n",
    "                                                      montage_channels= montage_channels,\n",
    "                                                      echo=echo)\n",
    "            self.montages[dataset] = montage\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _dataset_specific_loading_and_montage(self,event_file,dataset):\n",
    "        path_signal = os.path.join(self.metadata[dataset]['path'],event_file+'.npy')\n",
    "        signal = np.load(path_signal)\n",
    "        signal = self.montages[dataset](signal)    \n",
    "        return signal\n",
    "    \n",
    "    def _preprocess(self,signal):\n",
    "        # cut window to desired shape\n",
    "        if self.windowcutter is not None:\n",
    "            signal = self.windowcutter(signal)\n",
    "        # apply transformations\n",
    "        if self.transform is not None:\n",
    "            signal = self.transform(signal)                \n",
    "        # normalize signal\n",
    "        if self.normalize==True:\n",
    "            signal = signal / (np.quantile(np.abs(signal), q=0.95, method=\"linear\", axis=-1, keepdims=True) + 1e-8)\n",
    "        # convert to torch tensor\n",
    "        # replace nan values with 0\n",
    "        signal = np.nan_to_num(signal)\n",
    "        signal = torch.FloatTensor(signal.copy())\n",
    "        \n",
    "        return signal\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get name and label of the idx-th sample\n",
    "        event_file = self.df.iloc[idx]['event_file']\n",
    "        label = self.df.iloc[idx]['fraction_of_yes']\n",
    "        # get dataset specific information\n",
    "        dataset = self.df.iloc[idx]['dataset']\n",
    "\n",
    "        # load signal of the idx-th sample\n",
    "        signal =self._dataset_specific_loading_and_montage(event_file,dataset)\n",
    "        # preprocess signal\n",
    "        signal = self._preprocess(signal)\n",
    "        # return signal    \n",
    "        return signal,label\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeletedChannelsDatamoduleWithMembers(pl.LightningDataModule):\n",
    "    def __init__(self,df,metadata,storage_channels,montage_channels,windowsize,windowjitter,Fq,batch_size,n_keeper_channels='random',keeper_channels='random',echo=True):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        if echo:\n",
    "            print('building datamodule!')\n",
    "            print(f'there are {len(df[df.Mode==\"Train\"])} test samples and {len(df[df.Mode==\"Val\"])} val samples')\n",
    "            print(f'the fraction of positive samples is {df.fraction_of_yes.sum()/len(df):.2f}\\n')\n",
    "\n",
    "        channel_deleter = choose_channel_deleter(n_keeper_channels,montage_channels,keeper_channels)        \n",
    "        # build deleter into dataset as a transformation!\n",
    "        transforms_all = transforms.Compose([channel_deleter])\n",
    "\n",
    "        # build montage and windowcutter\n",
    "        windowcutter = cut_and_jitter(windowsize=windowsize,max_offset=windowjitter,Fq=Fq)\n",
    "\n",
    "        self.dataset_train = MultiSourceSpikeDataset(df=self.df[self.df.Mode=='Train'],metadata = metadata,montage_channels=montage_channels, windowcutter = windowcutter,transform=transforms_all,normalize=True,echo=False)\n",
    "        self.dataset_val = MultiSourceSpikeDataset(df=self.df[self.df.Mode=='Val'],metadata = metadata,montage_channels=montage_channels, windowcutter = windowcutter,transform=transforms_all,normalize=True,echo=False)    \n",
    "        self.dataset_test = MultiSourceSpikeDataset(df=self.df[self.df.Mode=='Test'],metadata = metadata,montage_channels=montage_channels, windowcutter = windowcutter,transform=transforms_all,normalize=True,echo=False)\n",
    "       \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.dataset_train, batch_size=self.batch_size, shuffle=True, num_workers=os.cpu_count())\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.dataset_val, batch_size=self.batch_size, shuffle=False, num_workers=os.cpu_count())\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.dataset_test, batch_size=self.batch_size, shuffle=False, num_workers=os.cpu_count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = '../Models/generalized_ten-twenty-rep'\n",
    "with open(path_model+'/config.pkl', 'rb') as f:\n",
    "   config = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "path_signal = '/media/moritz/a80fe7e6-2bb9-4818-8add-17fb9bb673e1/Data/Bonobo/cluster_center/'\n",
    "df = pd.read_csv('/home/moritz/Desktop/programming/epilepsy_project/tables/bonobo/lut_event_23-08-22.csv')# fraction filter\n",
    "extreme_quality_filter = df['total_votes_received'] >= 8\n",
    "\n",
    "# test_df = df[frac_filter & mode_filter & extreme_quality_filter].copy()    \n",
    "# neg = test_df[test_df.fraction_of_yes<0.5]         \n",
    "# pos = test_df[test_df.fraction_of_yes>0.5][:len(neg)]\n",
    "# test_df = pd.concat([neg,pos])\n",
    "\n",
    "pos_auc_df = df[(df.Mode=='Test')&(df['fraction_of_yes'] >= /8) & extreme_quality_filter]\n",
    "neg_auc_df = df[(df.Mode=='Test')&(df.fraction_of_yes==0)][:len(pos_auc_df)]\n",
    "test_df = pd.concat([pos_auc_df,neg_auc_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model\n",
    "model = FineTuning.load_from_checkpoint(path_model+'/weights.ckpt',\n",
    "                                        lr=config.LR,\n",
    "                                        head_dropout=config.HEAD_DROPOUT,\n",
    "                                        n_channels=len(config.CHANNELS),\n",
    "                                        n_fft=config.N_FFT,\n",
    "                                        hop_length=config.HOP_LENGTH)\n",
    "                                    \n",
    "# init trainer\n",
    "trainer = pl.Trainer(fast_dev_run=False,enable_progress_bar=False,devices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storage channels: ['Fp1', 'F3', 'C3', 'P3', 'F7', 'T3', 'T5', 'O1', 'Fz', 'Cz', 'Pz', 'Fp2', 'F4', 'C4', 'P4', 'F8', 'T4', 'T6', 'O2']\n",
      "montage channels: ['Fp1', 'F3', 'C3', 'P3', 'F7', 'T3', 'T5', 'O1', 'Fz', 'Cz', 'Pz', 'Fp2', 'F4', 'C4', 'P4', 'F8', 'T4', 'T6', 'O2']\n"
     ]
    }
   ],
   "source": [
    "montage = build_montagev2(storage_channels=CDAC_mono_channels,montage_channels=config.CHANNELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# delete n random channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_datamodule_info():\n",
    "    datasets = {'center':dataset_center}\n",
    "    df,metadata = prepare_member_and_center_info(datasets)\n",
    "    storage_channels = all_referential\n",
    "    return df, metadata, storage_channels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_center():\n",
    "    # returns high confidence dataframe, path and storage channels\n",
    "    # Load Bonobo dataframe and add 'dataset' column\n",
    "    #df = pd.read_csv('../Data/tables/lut_event_23-08-22.csv')\n",
    "    df = pd.read_csv('../Data/tables/event_split_localized_08Feb24.csv')\n",
    "    df['dataset'] = 'center' \n",
    "    df = df[(df.total_votes_received>=3)|(df.fraction_of_yes==0)]\n",
    "    path = '/media/moritz/a80fe7e6-2bb9-4818-8add-17fb9bb673e1/Data/Bonobo/cluster_center/' \n",
    "    storage_channels = all_referential\n",
    "\n",
    "    return df, path, storage_channels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_member_and_center_info(datasets):\n",
    "    # input: list of dataset functions, each of which returns the datasets dataframe, location and storage chanel\n",
    "    # output: concatenated_dataframes + metadata dictionary\n",
    "    # Initialize empty list to collect dataframes\n",
    "    dfs = []\n",
    "    # Create empty dictionary to store dataset metadata\n",
    "    metadata = {}\n",
    "\n",
    "    \n",
    "\n",
    "    for dataset in datasets.keys():\n",
    "        datasets[dataset]()\n",
    "        df, path, storage_channels = datasets[dataset]()\n",
    "        dfs.append(df)\n",
    "        metadata[dataset]={}\n",
    "        metadata[dataset]['path']=path\n",
    "        metadata[dataset]['storage_channels']=storage_channels\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    df = df[['event_file','patient_id','total_votes_received','fraction_of_yes','Mode','dataset']]\n",
    "\n",
    "    print(f'\\n using the following datasets: {metadata.keys()} to build datamodule\\n')\n",
    "    # print how much data each dataset has\n",
    "    print(df.dataset.value_counts())\n",
    "    return df, metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filters(df):\n",
    "    pos = df[(df['fraction_of_yes'] >= 7/8) & (df.total_votes_received >=8) &(df.Mode=='Test')]\n",
    "    neg = df[(df.fraction_of_yes==0)&(df.Mode=='Test')]\n",
    "    N = min(len(pos),len(neg))\n",
    "    print(N)\n",
    "    df = pd.concat([pos[:N],neg[:N]])    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " using the following datasets: dict_keys(['center']) to build datamodule\n",
      "\n",
      "center    30394\n",
      "Name: dataset, dtype: int64\n",
      "1167\n"
     ]
    }
   ],
   "source": [
    "df, metadata, storage_channels = init_datamodule_info()\n",
    "df = apply_filters(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_channel_deleter(n_keeper_channels,montage_channels,keeper_channels):\n",
    "    # choose right channel deleter dependent on what type is desired\n",
    "    if n_keeper_channels=='random':\n",
    "        print('keeping random number of random channels!\\n')\n",
    "        channel_deleter = keep_random_number_of_random_channels(montage_channels=montage_channels)\n",
    "    elif (n_keeper_channels!='random')&(keeper_channels=='random'):\n",
    "        print(f'keeping {n_keeper_channels} random channels\\n')\n",
    "        channel_deleter = keep_fixed_number_of_random_channels(montage_channels=montage_channels,n_keeper_channels=n_keeper_channels)\n",
    "    elif (n_keeper_channels!='random')&(keeper_channels!='random'):\n",
    "        print(f'keeping the following channels: {keeper_channels}!\\n')\n",
    "        channel_deleter = keep_fixed_number_of_fixed_channels(montage_channels=montage_channels,keeper_channels=keeper_channels)\n",
    "\n",
    "    return channel_deleter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "class keep_fixed_number_of_random_channels():\n",
    "    # init with list of signal montage channels, number of channels to be retained\n",
    "    # use: input: signal\n",
    "    # output: zero masked signal with *fixed* number of random channels retained\n",
    "    def __init__(self,montage_channels,n_keeper_channels):\n",
    "        self.n_channels = len(montage_channels)\n",
    "        self.n_keeper_channels = n_keeper_channels\n",
    "    def __call__(self,signal):\n",
    "        # choose n random keeper_channels\n",
    "        keeper_indices = np.random.choice(self.n_channels, self.n_keeper_channels, replace=False)\n",
    "        # build output\n",
    "        output = np.zeros_like(signal)\n",
    "        output[keeper_indices,:] = signal[keeper_indices,:]\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for 0 kept channels\n",
      "building datamodule!\n",
      "there are 0 test samples and 0 val samples\n",
      "the fraction of positive samples is 0.47\n",
      "\n",
      "keeping 0 random channels\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "  5%|▌         | 1/20 [00:10<03:26, 10.84s/it]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for 1 kept channels\n",
      "building datamodule!\n",
      "there are 0 test samples and 0 val samples\n",
      "the fraction of positive samples is 0.47\n",
      "\n",
      "keeping 1 random channels\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      " 10%|█         | 2/20 [00:21<03:16, 10.91s/it]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for 2 kept channels\n",
      "building datamodule!\n",
      "there are 0 test samples and 0 val samples\n",
      "the fraction of positive samples is 0.47\n",
      "\n",
      "keeping 2 random channels\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      " 15%|█▌        | 3/20 [00:32<03:05, 10.90s/it]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for 3 kept channels\n",
      "building datamodule!\n",
      "there are 0 test samples and 0 val samples\n",
      "the fraction of positive samples is 0.47\n",
      "\n",
      "keeping 3 random channels\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      " 20%|██        | 4/20 [00:43<02:54, 10.90s/it]LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for 4 kept channels\n",
      "building datamodule!\n",
      "there are 0 test samples and 0 val samples\n",
      "the fraction of positive samples is 0.47\n",
      "\n",
      "keeping 4 random channels\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = {'n_keeper':[],'run':[],'AUC':[]} # store results here\n",
    "\n",
    "# get labels and convert them to binary labels (0.1 -> 0, 0.9 -> 1)\n",
    "labels = df.fraction_of_yes.round(0).astype(int)\n",
    "\n",
    "for n_keeper in tqdm(range(0,len(config.CHANNELS)+1)):\n",
    "    print(f'Running for {n_keeper} kept channels')\n",
    "    datamodule = DeletedChannelsDatamoduleWithMembers(df=df,\n",
    "                                                  storage_channels=all_referential,\n",
    "                                                  montage_channels=config.CHANNELS,\n",
    "                                                  Fq=config.FQ,\n",
    "                                                  metadata=metadata,\n",
    "                                                  windowsize=config.WINDOWSIZE,\n",
    "                                                  windowjitter=config.WINDOWJITTER,\n",
    "                                                  batch_size=config.BATCH_SIZE,\n",
    "                                                  n_keeper_channels=n_keeper,\n",
    "                                                  keeper_channels='random')\n",
    "    # predict on AUC dataset n times, as channel deletion is random\n",
    "    for run in range(5):\n",
    "        preds = trainer.predict(model,datamodule.test_dataloader())\n",
    "        preds = np.concatenate(preds)\n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(labels, preds)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        results['n_keeper'].append(n_keeper)\n",
    "        results['run'].append(run)\n",
    "        results['AUC'].append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMultiSourceSpikeDataset\u001b[39;00m(\u001b[43mDataset\u001b[49m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, df, metadata, montage_channels, windowcutter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,echo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m echo: \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuilding dataset from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetadata\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class MultiSourceSpikeDataset(Dataset):\n",
    "    def __init__(self, df, metadata, montage_channels, windowcutter = None,transform=None,normalize=False,echo=True):\n",
    "        \n",
    "        if echo: print(f'building dataset from {metadata.keys()}')\n",
    "        # set lookup table\n",
    "        self.df = df\n",
    "        # set metadata\n",
    "        self.metadata = metadata\n",
    "        # set transform\n",
    "        self.transform = transform\n",
    "        # set windowcutter\n",
    "        self.windowcutter = windowcutter\n",
    "        # set normalize\n",
    "        self.normalize = normalize\n",
    "        if echo:\n",
    "            if self.normalize: print('Dataloader normalizes!\\n')\n",
    "            else: print('Dataloader does not normalize!\\n')\n",
    "\n",
    "        # generate montages for all datasets\n",
    "        self.montages = {}\n",
    "        for dataset in metadata.keys():\n",
    "            if echo: print('build montage for dataset ' + dataset + ' ...')\n",
    "            montage = build_montage(storage_channels=metadata[dataset]['storage_channels'], \n",
    "                                                      montage_channels= montage_channels,\n",
    "                                                      echo=echo)\n",
    "            self.montages[dataset] = montage\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def _dataset_specific_loading_and_montage(self,event_file,dataset):\n",
    "        path_signal = os.path.join(self.metadata[dataset]['path'],event_file+'.npy')\n",
    "        signal = np.load(path_signal)\n",
    "        signal = self.montages[dataset](signal)    \n",
    "        return signal\n",
    "    \n",
    "    def _preprocess(self,signal):\n",
    "        # cut window to desired shape\n",
    "        if self.windowcutter is not None:\n",
    "            signal = self.windowcutter(signal)\n",
    "        # apply transformations\n",
    "        if self.transform is not None:\n",
    "            signal = self.transform(signal)                \n",
    "        # normalize signal\n",
    "        if self.normalize==True:\n",
    "            signal = signal / (np.quantile(np.abs(signal), q=0.95, method=\"linear\", axis=-1, keepdims=True) + 1e-8)\n",
    "        # convert to torch tensor\n",
    "        # replace nan values with 0\n",
    "        signal = np.nan_to_num(signal)\n",
    "        signal = torch.FloatTensor(signal.copy())\n",
    "        \n",
    "        return signal\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get name and label of the idx-th sample\n",
    "        event_file = self.df.iloc[idx]['event_file']\n",
    "        label = self.df.iloc[idx]['fraction_of_yes']\n",
    "        # get dataset specific information\n",
    "        dataset = self.df.iloc[idx]['dataset']\n",
    "\n",
    "        # load signal of the idx-th sample\n",
    "        signal =self._dataset_specific_loading_and_montage(event_file,dataset)\n",
    "        # preprocess signal\n",
    "        signal = self._preprocess(signal)\n",
    "        # return signal    \n",
    "        return signal,label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "deletion_results = pd.DataFrame(results)\n",
    "deletion_results.to_csv(path_model+'deletion_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'x' and 'y' must have the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m err \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_keeper\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstd()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# plt.plot(range(0,20),auc)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorbar\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mauc_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43myerr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxticks(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m20\u001b[39m))\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39myticks(np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0.5\u001b[39m,\u001b[38;5;241m1.01\u001b[39m,\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m20\u001b[39m))\n",
      "File \u001b[0;32m~/Desktop/programming/venv/lib/python3.10/site-packages/matplotlib/pyplot.py:3030\u001b[0m, in \u001b[0;36merrorbar\u001b[0;34m(x, y, yerr, xerr, fmt, ecolor, elinewidth, capsize, barsabove, lolims, uplims, xlolims, xuplims, errorevery, capthick, data, **kwargs)\u001b[0m\n\u001b[1;32m   3009\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39merrorbar)\n\u001b[1;32m   3010\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merrorbar\u001b[39m(\n\u001b[1;32m   3011\u001b[0m     x: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3028\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3029\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ErrorbarContainer:\n\u001b[0;32m-> 3030\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorbar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3031\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3032\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3033\u001b[0m \u001b[43m        \u001b[49m\u001b[43myerr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myerr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3034\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxerr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxerr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3035\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3036\u001b[0m \u001b[43m        \u001b[49m\u001b[43mecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3037\u001b[0m \u001b[43m        \u001b[49m\u001b[43melinewidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melinewidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3038\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapsize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3039\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbarsabove\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbarsabove\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3040\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlolims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlolims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3041\u001b[0m \u001b[43m        \u001b[49m\u001b[43muplims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muplims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3042\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxlolims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxlolims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3043\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxuplims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxuplims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3044\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrorevery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrorevery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapthick\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapthick\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3046\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3047\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3048\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/programming/venv/lib/python3.10/site-packages/matplotlib/__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1467\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1468\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1469\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/Desktop/programming/venv/lib/python3.10/site-packages/matplotlib/axes/_axes.py:3569\u001b[0m, in \u001b[0;36mAxes.errorbar\u001b[0;34m(self, x, y, yerr, xerr, fmt, ecolor, elinewidth, capsize, barsabove, lolims, uplims, xlolims, xuplims, errorevery, capthick, **kwargs)\u001b[0m\n\u001b[1;32m   3567\u001b[0m x, y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(x, y)  \u001b[38;5;66;03m# Make sure all the args are iterable.\u001b[39;00m\n\u001b[1;32m   3568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y):\n\u001b[0;32m-> 3569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must have the same size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3571\u001b[0m everymask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_errorevery_to_mask(x, errorevery)\n\u001b[1;32m   3573\u001b[0m label \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: 'x' and 'y' must have the same size"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc_value = pd.DataFrame(results).groupby('n_keeper')['AUC'].mean()\n",
    "err = pd.DataFrame(results).groupby('n_keeper')['AUC'].std()\n",
    "# plt.plot(range(0,20),auc)\n",
    "plt.errorbar(range(0,20),auc_value,yerr=err)\n",
    "plt.xticks(range(0,20))\n",
    "plt.yticks(np.arange(0.5,1.01,1/20))\n",
    "plt.tight_layout()\n",
    "plt.ylabel('easyAUC')\n",
    "plt.xlabel('n channels retained')\n",
    "plt.title(f'random channels retained, n = {len(test_df)}')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0.5,1,1/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[test_df.fraction_of_yes<0.5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
